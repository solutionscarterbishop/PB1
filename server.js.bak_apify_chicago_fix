// server.js (PB1) ‚Äî COPY/PASTE ENTIRE FILE
// ESM module (requires: "type":"module" in package.json)

import "dotenv/config";
import express from "express";
import cors from "cors";
import crypto from "crypto";
import { createClient } from "@supabase/supabase-js";

const app = express();
const PORT = process.env.PORT || 10000;

// ----- Fingerprints (so you always know what's running) -----
const BUILD = process.env.BUILD || "PB1_SERVER_BUILD__2026-01-17__APIFY_LOCK";

console.log("‚úÖ SERVER FILE:", new URL(import.meta.url).pathname);
console.log("‚úÖ SERVER BUILD:", BUILD);
console.log("‚úÖ SERVER START:", new Date().toISOString());

// ----- Config -----
const SUPABASE_URL = process.env.SUPABASE_URL;
const SUPABASE_SERVICE_ROLE_KEY = process.env.SUPABASE_SERVICE_ROLE_KEY;
const APIFY_TOKEN = process.env.APIFY_TOKEN || "";

// required for ingest protection
const INGEST_TOKEN = (process.env.INGEST_TOKEN || "").trim();
console.log("üîê INGEST_TOKEN loaded?", INGEST_TOKEN ? "YES" : "NO", "len=", INGEST_TOKEN.length);

// Table/View names (match your Supabase schema)
const CFG = {
  EXEC_WEEKLY: process.env.EXEC_WEEKLY_TABLE || "exec_weekly",
  STORES: process.env.STORES_TABLE || "stores",
  REVIEWS: process.env.REVIEWS_TABLE || "reviews",
  INGEST_EVENTS: process.env.INGEST_EVENTS_TABLE || "ingest_events",
  // optional RPC to refresh rollups (only runs if present and exists)
  RPC_REFRESH_ROLLUPS: process.env.RPC_REFRESH_ROLLUPS || "refresh_rollups",
};

const supabase =
  SUPABASE_URL && SUPABASE_SERVICE_ROLE_KEY
    ? createClient(SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY)
    : null;

if (!SUPABASE_URL || !SUPABASE_SERVICE_ROLE_KEY) {
  console.error("‚ö†Ô∏è Missing SUPABASE_URL or SUPABASE_SERVICE_ROLE_KEY in .env");
}

// ----- Middleware -----
app.set("etag", false);
app.use(
  cors({
    origin: "*",
    methods: ["GET", "POST", "OPTIONS"],
    allowedHeaders: ["Content-Type", "X-Ingest-Token"],
    maxAge: 86400,
  })
);
app.use(express.json({ limit: "2mb" }));

// Prevent caching on API routes (avoid 304/body issues)
app.use("/api", function (_req, res, next) {
  res.setHeader("Cache-Control", "no-store, no-cache, must-revalidate, proxy-revalidate");
  res.setHeader("Pragma", "no-cache");
  res.setHeader("Expires", "0");
  next();
});

// ----- Helpers -----
const ALLOWED_SOURCES = ["apify"];

function norm(x) {
  return (x ?? "").toString().trim().toLowerCase();
}
function isApifySource(s) {
  return norm(s).includes("apify");
}
function nowIso() {
  return new Date().toISOString();
}
function respondError(res, signature, error, status = 500, extra = {}) {
  res.status(status).json({
    ok: false,
    signature,
    build: BUILD,
    last_updated: nowIso(),
    error,
    ...extra,
  });
}
function enforceApifySourceParam(req, res, signature) {
  const raw = (req.query.source ?? "").toString().trim();
  const normalized = norm(raw);
  if (raw && normalized !== "apify") {
    respondError(res, signature, "source_not_allowed", 400, { allowed: ALLOWED_SOURCES });
    return null;
  }
  return "apify";
}
function applyApifySourceFilter(q) {
  return q.ilike("source", "%apify%");
}
function isWeekString(v) {
  return /^\d{4}-\d{2}-\d{2}$/.test(String(v || ""));
}
function normalizeState(input) {
  const s = String(input || "").trim();
  if (!s) return { raw: null, code: null, name: null };
  const up = s.toUpperCase();
  const map = {
    AL: "Alabama", AK: "Alaska", AZ: "Arizona", AR: "Arkansas", CA: "California", CO: "Colorado", CT: "Connecticut",
    DE: "Delaware", FL: "Florida", GA: "Georgia", HI: "Hawaii", ID: "Idaho", IL: "Illinois", IN: "Indiana", IA: "Iowa",
    KS: "Kansas", KY: "Kentucky", LA: "Louisiana", ME: "Maine", MD: "Maryland", MA: "Massachusetts", MI: "Michigan",
    MN: "Minnesota", MS: "Mississippi", MO: "Missouri", MT: "Montana", NE: "Nebraska", NV: "Nevada", NH: "New Hampshire",
    NJ: "New Jersey", NM: "New Mexico", NY: "New York", NC: "North Carolina", ND: "North Dakota", OH: "Ohio", OK: "Oklahoma",
    OR: "Oregon", PA: "Pennsylvania", RI: "Rhode Island", SC: "South Carolina", SD: "South Dakota", TN: "Tennessee",
    TX: "Texas", UT: "Utah", VT: "Vermont", VA: "Virginia", WA: "Washington", WV: "West Virginia", WI: "Wisconsin", WY: "Wyoming"
  };
  if (up.length === 2 && map[up]) return { raw: s, code: up, name: map[up] };
  // if user typed full name already
  return { raw: s, code: map[up] ? up : null, name: s };
}
function parseMarketFilters(req) {
  const stateRaw = (req.query.state || "").toString().trim();
  const cityRaw  = (req.query.city  || "").toString().trim();

  return {
    state: stateRaw ? normalizeState(stateRaw) : null, // object {raw,code,name}
    city: cityRaw || null
  };
}

function applyMarketFilters(q, { state, city } = {}) {
  let out = q;
  const name = state?.name || null;
  const code = state?.code || null;
  if (name && code) {
    out = out.or(`state.ilike.%${name}%,state.ilike.%${code}%`);
  } else if (name) {
    out = out.ilike("state", `%${name}%`);
  }
  if (city) out = out.ilike("city", city);
  return out;
}
function parseLimit(raw, fallback, max) {
  const n = Number(raw);
  if (!Number.isFinite(n) || n <= 0) return fallback;
  return Math.min(Math.floor(n), max);
}
function sha1(s) {
  return crypto.createHash("sha1").update(String(s)).digest("hex");
}
function isUuid(v) {
  return /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i.test(
    String(v || "")
  );
}
async function storeIdExists(id) {
  if (!supabase) return false;
  const res = await supabase.from(CFG.STORES).select("id").eq("id", id).limit(1);
  if (res.error) return false;
  return (res.data || []).length > 0;
}
function normalizeAddress(s) {
  return String(s || "")
    .toLowerCase()
    .replace(/[^\w\s]/g, " ")
    .replace(/\s+/g, " ")
    .trim();
}

async function inferColumns(tableName) {
  try {
    const result = await supabase.from(tableName).select("*").limit(1);
    if (result.error) return { error: result.error.message || String(result.error) };
    const row = (result.data || [])[0];
    if (!row) return [];
    return Object.keys(row);
  } catch (e) {
    return { error: e?.message || String(e) };
  }
}

function requireSupabase(res, signature) {
  if (!supabase) {
    respondError(res, signature, "supabase_not_configured", 500);
    return false;
  }
  return true;
}
function requireIngestToken(req, res, signature) {
  // Fail closed if you forgot to set it (safer)
  if (!INGEST_TOKEN) {
    respondError(res, signature, "ingest_token_not_configured", 403);
    return false;
  }

  const headerToken = (req.get("x-ingest-token") || "").trim();
  const queryToken = (req.query?.token || "").toString().trim();
  const token = headerToken || queryToken;

  if (!token || token !== INGEST_TOKEN) {
    respondError(res, signature, "invalid_ingest_token", 403);
    return false;
  }
  return true;
}
async function refreshRollupsSafe() {
  try {
    if (!supabase) return;
    const rpcName = (CFG.RPC_REFRESH_ROLLUPS || "").trim();
    if (!rpcName) return;

    const r = await supabase.rpc(rpcName);
    if (r.error) {
      console.warn("‚ö†Ô∏è rollup refresh warning:", r.error.message || r.error);
    }
  } catch (e) {
    console.warn("‚ö†Ô∏è rollup refresh exception:", e?.message || e);
  }
}

// Very light in-memory limiter for ingest endpoints
const ingestWindowMs = 60_000;
const ingestMax = 60;
const ingestHits = new Map();
function createIngestLimiter(signature) {
  return function ingestLimiter(req, res, next) {
    const key = (req.headers["x-forwarded-for"] || req.socket.remoteAddress || "unknown").toString();
    const now = Date.now();
    const rec = ingestHits.get(key) || { n: 0, t: now };

    if (now - rec.t > ingestWindowMs) {
      rec.n = 0;
      rec.t = now;
    }

    rec.n += 1;
    ingestHits.set(key, rec);

    if (rec.n > ingestMax) {
      return respondError(res, signature, "rate_limited", 429);
    }

    next();
  };
}

function sendExecWeekly(res, rowsRaw, filters) {
  const rows = rowsRaw ?? [];
  const week_ending = filters.week || (rows[0]?.week_ending ?? null);

  let totalReviews = 0;
  let weightedSum = 0;
  const storeSet = new Set();

  for (const r of rows) {
    const tr = Number(r.total_reviews ?? r.total ?? 0) || 0;
    const ar = Number(r.avg_rating ?? r.avg_stars ?? r.avg ?? 0) || 0;

    totalReviews += tr;
    weightedSum += ar * tr;

    const sid = r.store_id ?? "";
    if (sid) storeSet.add(sid);
  }

  const storesReporting = storeSet.size;

  const avgRatingOverall =
    totalReviews > 0
      ? weightedSum / totalReviews
      : rows.length
        ? rows.reduce((acc, r) => acc + (Number(r.avg_rating ?? r.avg_stars ?? r.avg ?? 0) || 0), 0) /
          rows.length
        : 0;

  res.json({
    ok: true,
    signature: "EXEC_WEEKLY_V1",
    build: BUILD,
    last_updated: nowIso(),
    records: rows.length,
    week_ending,
    kpis: {
      total_reviews: totalReviews,
      stores_reporting: storesReporting,
      avg_stars_overall: Number(avgRatingOverall.toFixed(2)),
    },
    meta: {
      filtersApplied: {
        week: filters.week ?? null,
        store: filters.store ?? null,
        state: filters.state ?? null,
        city: filters.city ?? null,
        sourceRequested: filters.sourceRequested ?? null,
      },
      counts: {
        weeklyRows: rows.length,
      },
    },
    rows,
  });
}

// ----- Basic health -----
app.get("/health", (_req, res) => res.send("ok"));
app.get("/api/health", (_req, res) =>
  res.json({ ok: true, signature: "HEALTH_V1", build: BUILD, last_updated: nowIso() })
);

// ----- Debug -----
app.get("/api/debug", async (req, res) => {
  try {
    if (!requireSupabase(res, "DEBUG_V1")) return;

    const filters = parseMarketFilters(req);
    const normalizedState = filters.state?.name || filters.state?.code ? filters.state : null;
    const reviewsColumns = await inferColumns(CFG.REVIEWS);
    const execWeeklyColumns = await inferColumns(CFG.EXEC_WEEKLY);

    let storesQuery = supabase.from(CFG.STORES).select("store_id", { count: "exact", head: true });
    storesQuery = applyMarketFilters(storesQuery, filters);
    const stores = await storesQuery;
    if (stores.error) throw stores.error;

    const storeIds = [];
    if (filters.state || filters.city) {
      const storeIdQuery = applyMarketFilters(
        supabase.from(CFG.STORES).select("store_id").limit(5000),
        filters
      );
      const storeIdResult = await storeIdQuery;
      if (storeIdResult.error) throw storeIdResult.error;
      storeIds.push(...(storeIdResult.data || []).map((r) => r.store_id).filter(Boolean));
    }

    let reviewsQuery = supabase.from(CFG.REVIEWS).select("external_id", { count: "exact", head: true });
    if (storeIds.length) reviewsQuery = reviewsQuery.in("store_id", storeIds);
    const reviews = await reviewsQuery;
    if (reviews.error) throw reviews.error;

    let execWeeklyQuery = supabase
      .from(CFG.EXEC_WEEKLY)
      .select("week_ending")
      .order("week_ending", { ascending: false })
      .limit(5000);
    execWeeklyQuery = applyMarketFilters(execWeeklyQuery, filters);
    const execWeekly = await execWeeklyQuery;
    if (execWeekly.error) throw execWeekly.error;

    const ingestEvents = await supabase
      .from(CFG.INGEST_EVENTS)
      .select("id", { count: "exact", head: true });

    const execRows = execWeekly.data ?? [];

    const weeks = [...new Set(execRows.map((r) => r.week_ending).filter(Boolean))];

    res.json({
      ok: true,
      signature: "DEBUG_V1",
      build: BUILD,
      last_updated: nowIso(),
      storesCount: stores.count ?? null,
      execWeeklyRowsCount: execRows.length,
      reviewsCount: reviews.count ?? null,
      ingestEventsCount: ingestEvents.count ?? null,
      weeks,
      inferredColumns: {
        reviews: reviewsColumns,
        exec_weekly: execWeeklyColumns,
      },
      meta: {
        filtersApplied: {
          state: filters.state?.raw ?? null,
          city: filters.city ?? null,
          normalizedState,
        },
        counts: {
          stores: stores.count ?? null,
          weeklyRows: execRows.length,
          reviews: reviews.count ?? null,
        },
      },
    });
  } catch (e) {
    console.error("‚ùå /api/debug error:", e);
    res.status(500).json({
      ok: false,
      signature: "DEBUG_V1",
      build: BUILD,
      last_updated: new Date().toISOString(),
      error: "server_error",
      error_detail: e?.message || String(e),
      stack: process.env.NODE_ENV === "production" ? undefined : e?.stack,
    });
  }
});

// ---------- /api/reviews ----------
app.get("/api/reviews", async (req, res) => {
  try {
    if (!requireSupabase(res, "REVIEWS_V1")) return;

    const limitRaw = req.query.limit;
    if (limitRaw != null && String(limitRaw).trim() !== "") {
      const limitNum = Number(limitRaw);
      if (!Number.isFinite(limitNum) || limitNum <= 0) {
        return respondError(res, "REVIEWS_V1", "invalid_limit", 400);
      }
    }
    const limit = parseLimit(req.query.limit ?? 60, 60, 200);

    // accept BOTH store_id and store
    const store_id = (req.query.store_id || req.query.store || "").toString().trim() || null;

    if (store_id && !isUuid(store_id)) {
      return respondError(res, "REVIEWS_V1", "invalid_store_id", 400);
    }

    const sourceRaw = (req.query.source ?? "").toString().trim();
    const sourceNorm = sourceRaw.toLowerCase();
    const wantsSourceFilter = Boolean(sourceRaw) && sourceNorm !== "all";
    const reviewsColumns = await inferColumns(CFG.REVIEWS);
    const hasSourceColumn = Array.isArray(reviewsColumns) && reviewsColumns.includes("source");
    const cityFilter = (req.query.city || "").toString().trim();
    const stateFilter = (req.query.state || "").toString().trim();

    const baseFields = ["store_id", "reviewer_name", "rating", "review_text", "review_date", "url"];
    if (hasSourceColumn) baseFields.splice(1, 0, "source");

    const runQuery = async (storeIdOverride) => {
      let q = supabase.from(CFG.REVIEWS).select(baseFields.join(", ")).order("review_date", {
        ascending: false,
      });
      if (storeIdOverride) q = q.eq("store_id", storeIdOverride);
      if (cityFilter) q = q.ilike("city", `%${cityFilter}%`);
      if (stateFilter) q = q.ilike("state", `%${stateFilter}%`);
      if (wantsSourceFilter && hasSourceColumn) q = q.eq("source", sourceRaw);
      return q.limit(limit);
    };

    let data = [];
    let storeIdResolvedTo = null;

    if (store_id) {
      const first = await runQuery(store_id);
      if (first.error) throw first.error;
      data = first.data ?? [];

      if (!data.length && isUuid(store_id)) {
        const byExternal = await supabase
          .from(CFG.STORES)
          .select("id")
          .eq("store_id", store_id)
          .limit(1);
        if (byExternal.error) throw byExternal.error;
        const resolvedExternalId = (byExternal.data || [])[0]?.id || null;
        if (resolvedExternalId) {
          const second = await runQuery(resolvedExternalId);
          if (second.error) throw second.error;
          data = second.data ?? [];
          if (data.length) storeIdResolvedTo = resolvedExternalId;
        }
      }

      if (data.length && !storeIdResolvedTo) storeIdResolvedTo = store_id;
    } else {
      const first = await runQuery(null);
      if (first.error) throw first.error;
      data = first.data ?? [];
    }

    res.json({
      ok: true,
      signature: "REVIEWS_V1",
      build: BUILD,
      last_updated: nowIso(),
      records: (data ?? []).length,
      filters: {
        limit,
        store_id: store_id ?? null,
        source: wantsSourceFilter && hasSourceColumn ? sourceRaw : null,
        state: stateFilter || null,
        city: cityFilter || null,
        store_id_resolved_to: storeIdResolvedTo,
      },
      rows: data ?? [],
    });
  } catch (e) {
    console.error("‚ùå /api/reviews error:", e);
    respondError(res, "REVIEWS_V1", "server_error", 500);
  }
});

// ---------- /api/exec-weekly ----------
app.get("/api/exec-weekly", async (req, res) => {
  try {
    if (!requireSupabase(res, "EXEC_WEEKLY_V1")) return;

    const week = norm(req.query.week) || null;
    const store = (req.query.store || req.query.store_id || "").toString().trim() || null;
    const sourceRequested = (req.query.source ?? "").toString().trim() || null;
    const filters = parseMarketFilters(req);
    const state = filters.state?.name || null;
    const code = filters.state?.code || null;
    const stateRaw = filters.state?.raw ?? null;
    const city = filters.city;

    if (week && !isWeekString(week)) {
      return respondError(res, "EXEC_WEEKLY_V1", "invalid_week_format", 400);
    }
    if (store && !isUuid(store)) {
      return respondError(res, "EXEC_WEEKLY_V1", "invalid_store_id", 400);
    }

    const limitRaw = req.query.limit;
    if (limitRaw != null && String(limitRaw).trim() !== "") {
      const limitNum = Number(limitRaw);
      if (!Number.isFinite(limitNum) || limitNum <= 0) {
        return respondError(res, "EXEC_WEEKLY_V1", "invalid_limit", 400);
      }
    }
    const limit = parseLimit(req.query.limit ?? 5000, 5000, 5000);

    const MIN_STORES = Number(process.env.MIN_STORES_FOR_LATEST_WEEK || 2);

    let storeIds = null;
    const useMarketStoreIds = Boolean(city) && !store;
    if (useMarketStoreIds) {
      let sq = supabase.from(CFG.STORES).select("id");
      sq = applyMarketFilters(sq, filters);
      const sres = await sq;
      if (sres.error) throw sres.error;
      storeIds = (sres.data || []).map((r) => r.id).filter(Boolean);
      if (!storeIds.length) {
        return sendExecWeekly(res, [], {
          week: week ?? null,
          store,
          state: stateRaw,
          city,
          sourceRequested,
        });
      }
    }

    const getMarketStoreIdsForReviews = async () => {
      if (store) return null;
      if (!filters.state && !filters.city) return null;
      let sq = supabase.from(CFG.STORES).select("id");
      sq = applyMarketFilters(sq, filters);
      const sres = await sq;
      if (sres.error) throw sres.error;
      return (sres.data || []).map((r) => r.id).filter(Boolean);
    };

    const buildWeeklyFromReviews = async (targetWeek) => {
      const marketStoreIds = store ? null : storeIds || (await getMarketStoreIdsForReviews());
      let rq = supabase.from(CFG.REVIEWS).select("store_id,rating,review_date,created_at");
      if (store) {
        rq = rq.eq("store_id", store);
      } else if (marketStoreIds && marketStoreIds.length) {
        rq = rq.in("store_id", marketStoreIds);
      }
      const reviewsRes = await rq.limit(10000);
      if (reviewsRes.error) throw reviewsRes.error;
      const reviewsRows = reviewsRes.data ?? [];

      const storeIdSet = new Set(reviewsRows.map((r) => r.store_id).filter(Boolean));
      const storeMap = new Map();
      if (storeIdSet.size) {
        const storeIdList = Array.from(storeIdSet);
        const storesRes = await supabase
          .from(CFG.STORES)
          .select("id,name,state,city")
          .in("id", storeIdList);
        if (storesRes.error) throw storesRes.error;
        for (const s of storesRes.data || []) {
          storeMap.set(s.id, s);
        }
      }

      const rollups = new Map();
      const toWeekEnding = (dateStr) => {
        const d = new Date(dateStr);
        if (Number.isNaN(d.getTime())) return null;
        const day = d.getUTCDay();
        const offset = day === 0 ? 0 : 7 - day;
        d.setUTCDate(d.getUTCDate() + offset);
        return d.toISOString().slice(0, 10);
      };

      for (const r of reviewsRows) {
        const dateStr = r.review_date || r.created_at || null;
        if (!dateStr) continue;
        const weekEnding = toWeekEnding(dateStr);
        if (!weekEnding) continue;
        if (targetWeek && weekEnding !== targetWeek) continue;

        const key = `${r.store_id}|${weekEnding}`;
        if (!rollups.has(key)) {
          const storeInfo = storeMap.get(r.store_id) || {};
          rollups.set(key, {
            store_id: r.store_id,
            week_ending: weekEnding,
            avg_rating: 0,
            total_reviews: 0,
            low_reviews: 0,
            high_reviews: 0,
            store_name: storeInfo.name || null,
            state: storeInfo.state || null,
            city: storeInfo.city || null,
            _rating_sum: 0,
            _rating_count: 0,
          });
        }

        const rec = rollups.get(key);
        rec.total_reviews += 1;
        const ratingNum = Number(r.rating);
        if (Number.isFinite(ratingNum)) {
          rec._rating_sum += ratingNum;
          rec._rating_count += 1;
          if (ratingNum <= 2) rec.low_reviews += 1;
          if (ratingNum >= 4) rec.high_reviews += 1;
        }
      }

      const rows = [];
      for (const rec of rollups.values()) {
        rec.avg_rating =
          rec._rating_count > 0 ? Number((rec._rating_sum / rec._rating_count).toFixed(2)) : 0;
        delete rec._rating_sum;
        delete rec._rating_count;
        rows.push(rec);
      }
      return rows;
    };

    const applyExecWeeklyFilters = (q) => {
      let out = q;
      if (store) {
        out = out.eq("store_id", store);
      } else if (storeIds && storeIds.length) {
        out = out.in("store_id", storeIds);
      }
      if (!useMarketStoreIds && (state || code)) {
        out = applyMarketFilters(out, { state: { name: state, code }, city: null });
      }
      return out;
    };

    const buildWeekQuery = (w) => {
      let q = supabase.from(CFG.EXEC_WEEKLY).select("*").eq("week_ending", w);
      q = applyExecWeeklyFilters(q);
      return q.order("week_ending", { ascending: false });
    };

    // If user explicitly asked for a week, fetch it (no fallback)
    if (week) {
      const { data, error } = await buildWeekQuery(week).limit(limit);
      if (error) throw error;
      const rows = data ?? [];
      if (!rows.length) {
        const fallbackRows = await buildWeeklyFromReviews(week);
        if (fallbackRows.length) {
          return sendExecWeekly(res, fallbackRows, {
            week,
            store,
            state: stateRaw,
            city,
            sourceRequested,
          });
        }
      }
      return sendExecWeekly(res, rows, {
        week,
        store,
        state: stateRaw,
        city,
        sourceRequested,
      });
    }

    // No week -> find candidate weeks newest->oldest
    let weeks = [];
    let attemptWeeks = supabase
      .from(CFG.EXEC_WEEKLY)
      .select("week_ending")
      .order("week_ending", { ascending: false })
      .limit(5000);
    const attemptWeeksResult = await attemptWeeks;

    if (attemptWeeksResult.error) {
      throw attemptWeeksResult.error;
    } else {
      weeks = [...new Set((attemptWeeksResult.data ?? []).map((r) => r.week_ending).filter(Boolean))];
    }

    if (!weeks.length) {
      const fallbackRows = await buildWeeklyFromReviews(null);
      if (fallbackRows.length) {
        const latestWeek = fallbackRows
          .map((r) => r.week_ending)
          .filter(Boolean)
          .sort()
          .slice(-1)[0];
        const finalRows = latestWeek
          ? fallbackRows.filter((r) => r.week_ending === latestWeek)
          : fallbackRows;
        return sendExecWeekly(res, finalRows, {
          week: latestWeek ?? null,
          store,
          state: stateRaw,
          city,
          sourceRequested,
        });
      }
      return sendExecWeekly(res, [], { week: null, store, state: stateRaw, city, sourceRequested });
    }

    // Choose effective week: first week with >= MIN_STORES rows (after filters)
    let effectiveWeek = null;
    for (const w of weeks) {
      const { data, error } = await buildWeekQuery(w).limit(limit);
      if (error) throw error;
      const rows = data ?? [];
      if (rows.length >= MIN_STORES) {
        effectiveWeek = w;
        break;
      }
    }
    if (!effectiveWeek) effectiveWeek = weeks[0] || null;

    if (!effectiveWeek) {
      return sendExecWeekly(res, [], { week: null, store, state: stateRaw, city, sourceRequested });
    }

    const { data: finalRows, error: finalErr } = await buildWeekQuery(effectiveWeek).limit(limit);
    if (finalErr) throw finalErr;

    const rows = finalRows ?? [];
    if (!rows.length) {
      const fallbackRows = await buildWeeklyFromReviews(effectiveWeek);
      if (fallbackRows.length) {
        return sendExecWeekly(res, fallbackRows, {
          week: effectiveWeek,
          store,
          state: stateRaw,
          city,
          sourceRequested,
        });
      }
    }

    return sendExecWeekly(res, rows, {
      week: effectiveWeek,
      store,
      state: stateRaw,
      city,
      sourceRequested,
    });
  } catch (e) {
    console.error("‚ùå /api/exec-weekly error FULL:", e);
    respondError(res, "EXEC_WEEKLY_V1", "server_error", 500, {
      error_detail: e?.message || String(e),
    });
  }
});

// ---------- /api/meta ----------
app.get("/api/meta", async (_req, res) => {
  try {
    if (!requireSupabase(res, "META_V1")) return;

    let data = null;

    const attempt = await supabase
      .from(CFG.EXEC_WEEKLY)
      .select("week_ending, source")
      .ilike("source", "%apify%")
      .order("week_ending", { ascending: false })
      .limit(5000);

    if (attempt.error && (attempt.error.message || "").toLowerCase().includes("source")) {
      const retry = await supabase
        .from(CFG.EXEC_WEEKLY)
        .select("week_ending")
        .order("week_ending", { ascending: false })
        .limit(5000);

      if (retry.error) throw retry.error;
      data = retry.data ?? [];
    } else if (attempt.error) {
      throw attempt.error;
    } else {
      data = attempt.data ?? [];
    }

    const weeks = [...new Set((data ?? []).map((r) => r.week_ending).filter(Boolean))];

    res.json({
      ok: true,
      signature: "META_V1",
      build: BUILD,
      last_updated: nowIso(),
      weeks,
      sources: ["apify"],
    });
  } catch (e) {
    console.error("‚ùå /api/meta error:", e);
    respondError(res, "META_V1", "server_error", 500);
  }
});

// ---------- /api/stores ----------
app.get("/api/stores", async (req, res) => {
  try {
    if (!requireSupabase(res, "STORES_V1")) return;

    const limitRaw = req.query.limit;
    if (limitRaw != null && String(limitRaw).trim() !== "") {
      const limitNum = Number(limitRaw);
      if (!Number.isFinite(limitNum) || limitNum <= 0) {
        return respondError(res, "STORES_V1", "invalid_limit", 400);
      }
    }
    const limit = parseLimit(req.query.limit ?? 500, 500, 2000);
    const filters = parseMarketFilters(req);

    let q = supabase
      .from(CFG.STORES)
      .select("store_id,id,name,address,city,state,created_at", { count: "exact" })
      .order("created_at", { ascending: false })
      .limit(limit);
    q = applyMarketFilters(q, filters);

    const { data, error, count } = await q;
    if (error) throw error;

    const rows = (data ?? []).map((r) => ({
      ...r,
      id: r.store_id || r.id || null,
    }));

    res.json({
      ok: true,
      signature: "STORES_V1",
      build: BUILD,
      last_updated: nowIso(),
      records: count ?? rows.length,
      rows,
      meta: {
        filtersApplied: {
          state: filters.state?.raw ?? null,
          city: filters.city ?? null,
        },
        counts: {
          stores: count ?? rows.length,
        },
      },
    });
  } catch (e) {
    console.error("‚ùå /api/stores error:", e);
    respondError(res, "STORES_V1", "server_error", 500);
  }
});

// ---------- /api/store/:store_id ----------
app.get("/api/store/:store_id", async (req, res) => {
  try {
    if (!requireSupabase(res, "STORE_V1_SHAPE")) return;

    const store_id = (req.params.store_id || "").toString().trim();
    if (!isUuid(store_id)) {
      return respondError(res, "STORE_V1_SHAPE", "invalid_store_id", 400);
    }

    // PB1_FIX_STORE_ID_V1
    const { data, error } = await supabase
      .from(CFG.STORES)
      .select("*")
      .or(`id.eq.${store_id},store_id.eq.${store_id}`)
      .limit(1);
    if (error) throw error;
    const row = (data || [])[0] || null;

    res.json({
      ok: true,
      signature: "STORE_V1_SHAPE",
      build: BUILD,
      last_updated: nowIso(),
      records: row ? 1 : 0,
              row,
             });

      return;
  } catch (e) {
    console.error("‚ùå /api/store/:store_id error:", e);
    respondError(res, "STORE_V1_SHAPE", "server_error", 500);
  }
});

// ---------- /api/stores/summary ----------
app.get("/api/stores/summary", async (_req, res) => {
  try {
    if (!requireSupabase(res, "STORES_SUMMARY_V1")) return;

    const attempt = await supabase
      .from(CFG.EXEC_WEEKLY)
      .select("week_ending, store_id, avg_rating, total_reviews, state, source")
      .ilike("source", "%apify%")
      .order("week_ending", { ascending: false })
      .limit(5000);

    let rows = null;

    if (attempt.error && (attempt.error.message || "").toLowerCase().includes("source")) {
      const retry = await supabase
        .from(CFG.EXEC_WEEKLY)
        .select("week_ending, store_id, avg_rating, total_reviews, state")
        .order("week_ending", { ascending: false })
        .limit(5000);
      if (retry.error) throw retry.error;
      rows = retry.data ?? [];
    } else if (attempt.error) {
      throw attempt.error;
    } else {
      rows = attempt.data ?? [];
    }

    const latestWeek = rows[0]?.week_ending ?? null;
    const latest = latestWeek ? rows.filter((r) => r.week_ending === latestWeek) : rows;
    const stores = new Set(latest.map((r) => r.store_id).filter(Boolean));

    res.json({
      ok: true,
      signature: "STORES_SUMMARY_V1",
      build: BUILD,
      last_updated: nowIso(),
      latest_week: latestWeek,
      stores_reporting: stores.size,
      records: latest.length,
    });
  } catch (e) {
    console.error("‚ùå /api/stores/summary error:", e);
    respondError(res, "STORES_SUMMARY_V1", "server_error", 500);
  }
});

// ---------- /api/metrics ----------
app.get("/api/metrics", async (req, res) => {
  const errorDetail = (err) => ({
    message: err?.message ?? null,
    code: err?.code ?? null,
    hint: err?.hint ?? null,
  });
  const respondMetricsError = (where, err) => {
    console.error("‚ùå /api/metrics error:", where, err);
    respondError(res, "METRICS_V1", "server_error", 500, {
      where,
      error_detail: errorDetail(err),
    });
  };

  try {
    if (!requireSupabase(res, "METRICS_V1")) return;

    const stateRaw = (req.query.state ?? "").toString().trim();
    const cityRaw = (req.query.city ?? "").toString().trim();
    const stateFilter = stateRaw || null;
    const cityFilter = cityRaw || null;
    const hasFilters = Boolean(stateFilter || cityFilter);
    const filtersApplied = { state: stateFilter, city: cityFilter };
    const reviewsColumns = await inferColumns(CFG.REVIEWS);
    const execWeeklyColumns = await inferColumns(CFG.EXEC_WEEKLY);

    let storesCount = null;
    let storeIds = [];
    try {
      if (hasFilters) {
        let storesQuery = supabase
          .from(CFG.STORES)
          .select("store_id,state,city", { count: "exact" });
        if (stateFilter) storesQuery = storesQuery.ilike("state", `%${stateFilter}%`);
        if (cityFilter) storesQuery = storesQuery.ilike("city", `%${cityFilter}%`);
        const storesRes = await storesQuery;
        if (storesRes.error) throw storesRes.error;
        storesCount = storesRes.count ?? null;
        storeIds = (storesRes.data ?? []).map((r) => r.store_id).filter(Boolean);
      } else {
        let storeCountQuery = supabase.from(CFG.STORES).select("store_id", { count: "exact", head: true });
        const storesRes = await storeCountQuery;
        if (storesRes.error) throw storesRes.error;
        storesCount = storesRes.count ?? null;
      }
    } catch (e) {
      return respondMetricsError("metrics:stores", e);
    }

    if (hasFilters && storeIds.length === 0) {
      return res.json({
        ok: true,
        signature: "METRICS_V1",
        build: BUILD,
        last_updated: nowIso(),
        storesCount: 0,
        reviewsCount: 0,
        execWeeklyRowsCount: 0,
        stores: 0,
        reviews: 0,
        exec_weekly_rows: 0,
        meta: {
          filtersApplied,
          storeIdsCount: 0,
          storeIdSample: [],
          inferredColumns: {
            reviews: reviewsColumns,
            exec_weekly: execWeeklyColumns,
          },
          counts: {
            stores: 0,
            reviews: 0,
            weeklyRows: 0,
          },
        },
      });
    }

    let reviewsCount = null;
    try {
      let reviewsQuery = supabase.from(CFG.REVIEWS).select("external_id", { count: "exact", head: true });
      if (storeIds.length) reviewsQuery = reviewsQuery.in("store_id", storeIds);
      const reviews = await reviewsQuery;
      if (reviews.error) throw reviews.error;
      reviewsCount = reviews.count ?? null;
    } catch (e) {
      return respondMetricsError("metrics:reviewsCount", e);
    }

    let execWeeklyRowsCount = null;
    try {
      let execWeeklyQuery = supabase
        .from(CFG.EXEC_WEEKLY)
        .select("week_ending", { count: "exact", head: true });
      if (storeIds.length) execWeeklyQuery = execWeeklyQuery.in("store_id", storeIds);
      const weeks = await execWeeklyQuery;
      if (weeks.error) throw weeks.error;
      execWeeklyRowsCount = weeks.count ?? null;
    } catch (e) {
      return respondMetricsError("metrics:execWeeklyCount", e);
    }

    res.json({
      ok: true,
      signature: "METRICS_V1",
      build: BUILD,
      last_updated: nowIso(),
      storesCount,
      reviewsCount,
      execWeeklyRowsCount,
      stores: storesCount,
      reviews: reviewsCount,
      exec_weekly_rows: execWeeklyRowsCount,
      meta: {
        filtersApplied,
        storeIdsCount: storeIds.length,
        storeIdSample: hasFilters ? storeIds.slice(0, 3) : [],
        inferredColumns: {
          reviews: reviewsColumns,
          exec_weekly: execWeeklyColumns,
        },
        counts: {
          stores: storesCount,
          reviews: reviewsCount,
          weeklyRows: execWeeklyRowsCount,
        },
      },
    });
  } catch (e) {
    return respondMetricsError("metrics:unknown", e);
  }
});

// ---------- /api/ingest/apify-reviews ----------
app.post("/api/ingest/apify-reviews", async (req, res) => {
  try {
    if (!requireSupabase(res, "INGEST_APIFY_REVIEWS_V1")) return;
    if (!APIFY_TOKEN) {
      return respondError(res, "INGEST_APIFY_REVIEWS_V1", "apify_token_not_configured", 500);
    }

    const datasetId = (req.body?.datasetId || "").toString().trim();
    const limitRaw = req.body?.limit;
    const limitNum = Number(limitRaw ?? 2000);
    const limit = Number.isFinite(limitNum) && limitNum > 0 ? Math.min(Math.floor(limitNum), 2000) : 2000;
    const source = (req.body?.source || "apify").toString().trim() || "apify";

    if (!datasetId) {
      return respondError(res, "INGEST_APIFY_REVIEWS_V1", "missing_dataset_id", 400);
    }

    const url =
      `https://api.apify.com/v2/datasets/${encodeURIComponent(datasetId)}/items` +
      `?clean=true&format=json&limit=${limit}&token=${encodeURIComponent(APIFY_TOKEN)}`;
    const resp = await fetch(url);
    if (!resp.ok) {
      return respondError(res, "INGEST_APIFY_REVIEWS_V1", "apify_fetch_failed", 502, {
        status: resp.status,
        status_text: resp.statusText,
      });
    }
    const items = await resp.json();
    const rowsRaw = Array.isArray(items) ? items : [];

    const firstItem = rowsRaw[0] || {};
    const firstKeys = Object.keys(firstItem || {});
    const hasPlaceKeys = ["title", "categoryName", "price", "neighborhood", "postalCode"].some((k) =>
      Object.prototype.hasOwnProperty.call(firstItem, k)
    );
    const hasReviewKeys = [
      "rating",
      "stars",
      "starRating",
      "reviewer_name",
      "reviewerName",
      "author",
      "userName",
      "name",
      "text",
      "textTranslated",
      "reviewText",
      "comment",
      "content",
      "date",
      "publishedAt",
      "published_at",
      "publishedAtDate",
      "review_date",
      "review_text",
    ].some((k) => Object.prototype.hasOwnProperty.call(firstItem, k));
    if (hasPlaceKeys && !hasReviewKeys) {
      return res.status(400).json({
        ok: false,
        signature: "INGEST_APIFY_REVIEWS_V1",
        error: "dataset_not_reviews",
        datasetId,
        hint:
          "This dataset looks like locations/places. Run a Google Reviews scraper actor and provide the datasetId containing individual reviews (rating/text/date/author).",
        firstKeys: firstKeys.slice(0, 40),
      });
    }

    const storeColumns = await inferColumns(CFG.STORES);
    const hasPlaceId = Array.isArray(storeColumns) && storeColumns.includes("place_id");
    const storeSelect = hasPlaceId
      ? "id,address,city,state,name,place_id"
      : "id,address,city,state,name";
    const storesRes = await supabase.from(CFG.STORES).select(storeSelect);
    if (storesRes.error) throw storesRes.error;
    const stores = storesRes.data ?? [];

    const byPlaceId = new Map();
    const byAddress = new Map();
    const storeIdSet = new Set();
    for (const s of stores) {
      if (s.id) storeIdSet.add(s.id);
      if (hasPlaceId && s.place_id) {
        byPlaceId.set(String(s.place_id).toLowerCase(), s);
      }
      if (s.address) {
        const key = normalizeAddress(s.address);
        if (key) byAddress.set(key, s);
      }
    }

    const reviewRows = [];
    const sampleUnmatched = [];
    let matched = 0;

    const extractReviewDate = (v) => {
      const str = String(v || "");
      const m = str.match(/\d{4}-\d{2}-\d{2}/);
      if (m) return m[0];
      const d = new Date(str);
      if (!Number.isNaN(d.getTime())) return d.toISOString().slice(0, 10);
      return null;
    };

    for (const item of rowsRaw) {
      const address =
        item?.address ||
        item?.location?.address ||
        item?.place?.address ||
        null;

      let storeMatch = null;
      if (hasPlaceId && item?.placeId && byPlaceId.has(String(item.placeId).toLowerCase())) {
        storeMatch = byPlaceId.get(String(item.placeId).toLowerCase());
      } else if (address) {
        const key = normalizeAddress(address);
        if (key && byAddress.has(key)) storeMatch = byAddress.get(key);
      }

      // PB1_FIX_STORE_ID_V1
      if (!storeMatch) {
        if (sampleUnmatched.length < 5) {
          sampleUnmatched.push({
            address: address || null,
            reviewer_name: item?.reviewer_name || item?.reviewerName || item?.author || item?.userName || null,
          });
        }
        continue;
      }

      if (!storeMatch.id || (!storeIdSet.has(storeMatch.id) && !(await storeIdExists(storeMatch.id)))) {
        return res.status(500).json({
          ok: false,
          signature: "INGEST_APIFY_REVIEWS_V1",
          error: "invalid_store_match_id",
          datasetId,
          sample: {
            placeId: item?.placeId || null,
            address: address || null,
          },
        });
      }

      matched += 1;
      const reviewerName =
        item?.name ||
        item?.reviewerName ||
        item?.reviewer_name ||
        item?.author ||
        item?.userName ||
        null;
      const rating = Number(item?.stars ?? item?.rating ?? item?.starRating ?? null);
      const reviewText =
        item?.text ||
        item?.textTranslated ||
        item?.reviewText ||
        item?.review_text ||
        item?.comment ||
        item?.content ||
        null;
      const reviewDate = extractReviewDate(
        item?.publishedAtDate ||
          item?.publishedAt ||
          item?.published_at ||
          item?.date ||
          item?.publishAt ||
          item?.scrapedAt ||
          null
      );
      const reviewUrl = item?.reviewUrl || item?.review_url || item?.url || item?.link || null;
      const placeName =
        item?.title || item?.place_name || item?.placeName || item?.locationName || null;

      const externalId =
        item?.reviewId ||
        item?.external_id ||
        item?.id ||
        sha1(
          [
            reviewerName || "",
            Number.isFinite(rating) ? String(rating) : "",
            reviewText || "",
            reviewDate || "",
            address || storeMatch.address || "",
            storeMatch.id || "",
          ].join("|")
        );

      reviewRows.push({
        store_id: storeMatch.id,
        source,
        reviewer_name: reviewerName,
        rating: Number.isFinite(rating) ? rating : null,
        review_text: reviewText,
        review_date: reviewDate,
        url: reviewUrl,
        external_id: externalId,
        city: item?.city || item?.location?.city || storeMatch.city || null,
        state: item?.state || item?.location?.state || storeMatch.state || null,
        place_name: placeName || storeMatch.name || null,
        address: address || storeMatch.address || null,
      });
    }

    if (!reviewRows.length) {
      return res.json({
        ok: true,
        signature: "INGEST_APIFY_REVIEWS_V1",
        datasetId,
        fetched: rowsRaw.length,
        matched,
        ingested: 0,
        unmatched: rowsRaw.length - matched,
        sample_unmatched: sampleUnmatched,
        last_updated: nowIso(),
      });
    }

    const sampleMapped = reviewRows.slice(0, 3).map((r) => ({
      store_id: r.store_id,
      reviewer_name: r.reviewer_name,
      rating: r.rating,
      review_date: r.review_date,
      url: r.url,
      external_id: r.external_id,
      review_text_preview: (r.review_text || "").slice(0, 80),
    }));
    console.log("INGEST_MAP_V2 sample:", sampleMapped[0]);

    const upsertRes = await supabase.from(CFG.REVIEWS).upsert(reviewRows, { onConflict: "external_id" });
    if (upsertRes.error) throw upsertRes.error;

    return res.json({
      ok: true,
      signature: "INGEST_APIFY_REVIEWS_V1",
      mapping_version: "APIFY_REVIEW_MAP_V2__2026-01-19",
      sample_first_keys: firstKeys.slice(0, 30),
      sample_mapped: sampleMapped,
      datasetId,
      fetched: rowsRaw.length,
      matched,
      ingested: reviewRows.length,
      unmatched: rowsRaw.length - matched,
      sample_unmatched: sampleUnmatched,
      last_updated: nowIso(),
    });
  } catch (e) {
    console.error("‚ùå /api/ingest/apify-reviews error:", e);
    return respondError(res, "INGEST_APIFY_REVIEWS_V1", "server_error", 500, {
      error_detail: e?.message || String(e),
    });
  }
});

// ---------- /api/admin/purge-bad-apify ----------
app.post("/api/admin/purge-bad-apify", async (req, res) => {
  try {
    if (!requireSupabase(res, "ADMIN_PURGE_BAD_APIFY_V1")) return;

    const del = await supabase
      .from(CFG.REVIEWS)
      .delete({ count: "exact" })
      .eq("source", "apify")
      .is("reviewer_name", null)
      .is("review_date", null)
      .ilike("url", "%query_place_id=%");
    if (del.error) throw del.error;

    res.json({
      ok: true,
      signature: "ADMIN_PURGE_BAD_APIFY_V1",
      deleted: del.count ?? 0,
    });
  } catch (e) {
    console.error("‚ùå /api/admin/purge-bad-apify error:", e);
    respondError(res, "ADMIN_PURGE_BAD_APIFY_V1", "server_error", 500, {
      error_detail: e?.message || String(e),
    });
  }
});

/*
Manual tests:
- Re-ingest: POST /api/ingest/apify-reviews datasetId AYqfTL4InXM8rHHQh
- Verify reviewer_name + review_date: GET /api/reviews?state=Illinois&city=Chicago&limit=5
- Verify external store_id works: GET /api/reviews?store_id=e3c2ef9a-736a-1b20-4edf-7798d6d56f59&limit=5
- Verify weekly: GET /api/exec-weekly?state=Illinois&city=Chicago&limit=50
*/

// ===============================
// INGEST (LOCKED) ENDPOINTS
// ===============================

// ---------- INGEST (LOCKED): /api/ingest/reviews ----------
app.post("/api/ingest/reviews", createIngestLimiter("INGEST_REVIEWS_V1"), async (req, res) => {
  try {
    if (!requireSupabase(res, "INGEST_REVIEWS_V1")) return;
    if (!requireIngestToken(req, res, "INGEST_REVIEWS_V1")) return;

    const reviews = req.body?.reviews || [];
    if (!Array.isArray(reviews) || !reviews.length) {
      return respondError(res, "INGEST_REVIEWS_V1", "missing_reviews_array", 400);
    }

    const rows = reviews
      .map((r) => {
        const store_id = r.store_id || r.storeId || null;

        // Guard: prevent Postgres uuid errors
        if (!store_id || !isUuid(store_id)) return null;

        const reviewer_name = r.reviewer_name || r.reviewerName || null;
        const review_text = r.review_text || r.reviewText || null;
        const review_date = r.review_date || r.reviewDate || null;

        return {
          store_id,
          source: r.source || "unknown",
          reviewer_name,
          rating: Number(r.rating ?? r.stars ?? 0) || null,
          review_text,
          review_date,
          url: r.url || r.reviewUrl || null,
          external_id:
            r.external_id ||
            r.externalId ||
            sha1(`${store_id}|${review_date}|${reviewer_name}|${review_text}`),
        };
      })
      .filter(Boolean);

    if (!rows.length) {
      return respondError(res, "INGEST_REVIEWS_V1", "no_valid_rows_store_id_must_be_uuid", 400);
    }

    const up = await supabase.from(CFG.REVIEWS).upsert(rows, { onConflict: "external_id" });
    if (up.error) throw up.error;

    await refreshRollupsSafe();

    res.json({
      ok: true,
      signature: "INGEST_REVIEWS_V1",
      build: BUILD,
      last_updated: nowIso(),
      ingested: rows.length,
    });
  } catch (e) {
    console.error("‚ùå /api/ingest/reviews error:", e);
    respondError(res, "INGEST_REVIEWS_V1", "server_error", 500);
  }
});

// ---------- INGEST (LOCKED): /api/ingest/apify ----------
// Webhook receiver (stores raw payload in ingest_events)
app.post("/api/ingest/apify", createIngestLimiter("INGEST_APIFY_V1"), async (req, res) => {
  try {
    if (!requireSupabase(res, "INGEST_APIFY_V1")) return;
    if (!requireIngestToken(req, res, "INGEST_APIFY_V1")) return;

    const payload = req.body ?? {};
    if (!payload || typeof payload !== "object") {
      return respondError(res, "INGEST_APIFY_V1", "invalid_payload", 400);
    }

    const received_at = new Date().toISOString();

    const ins = await supabase
      .from(CFG.INGEST_EVENTS)
      .insert([{ source: "apify", received_at, payload }])
      .select("id, received_at")
      .single();

    if (ins.error) throw ins.error;

    res.json({
      ok: true,
      signature: "INGEST_APIFY_V1",
      build: BUILD,
      last_updated: received_at,
      ingest_event: ins.data,
    });
  } catch (e) {
    console.error("‚ùå /api/ingest/apify error:", e);
    respondError(res, "INGEST_APIFY_V1", "server_error", 500);
  }
});

// ---------- INGEST (LOCKED): /api/ingest/apify/pull ----------
// Pull Apify DATASET and upsert into stores_apify (or whatever table you choose)
app.post("/api/ingest/apify/pull", createIngestLimiter("INGEST_APIFY_PULL_V1"), async (req, res) => {
  try {
    if (!requireSupabase(res, "INGEST_APIFY_PULL_V1")) return;
    if (!requireIngestToken(req, res, "INGEST_APIFY_PULL_V1")) return;

    const token = process.env.APIFY_TOKEN;
    const datasetId = process.env.APIFY_DATASET_ID;

    if (!token) return res.status(400).json({ ok: false, error: "Missing APIFY_TOKEN" });
    if (!datasetId) return res.status(400).json({ ok: false, error: "Missing APIFY_DATASET_ID" });

    const limit = Number(req.query.limit || 500);
    const url = `https://api.apify.com/v2/datasets/${datasetId}/items?clean=true&format=json&limit=${limit}&token=${token}`;

    const r = await fetch(url);
    const items = await r.json();

    if (!r.ok) {
      return res.status(r.status).json({ ok: false, error: "Apify fetch failed", status: r.status, body: items });
    }
    if (!Array.isArray(items)) {
      return res.status(500).json({ ok: false, error: "Apify returned non-array", body: items });
    }

    // NOTE: This mapping assumes your Apify items use the key names shown in your earlier curl output:
    // place_id, name, address, street, city, state, postalCode/postal_code, countryCode/country_code, lat/lng, total_score, reviews_count, scraped_at
    const rows = items.map((x) => ({
      source: "apify_google_maps",
      place_id: x.place_id || x.placeId || null,
      name: x.name || x.title || null,
      address: x.address || null,
      street: x.street || null,
      city: x.city || null,
      state: x.state || null,
      postal_code: x.postal_code || x.postalCode || null,
      country_code: x.country_code || x.countryCode || null,
      lat: x.lat ?? x.location?.lat ?? null,
      lng: x.lng ?? x.location?.lng ?? null,
      total_score: x.total_score ?? x.totalScore ?? null,
      reviews_count: x.reviews_count ?? x.reviewsCount ?? null,
      scraped_at: x.scraped_at
        ? new Date(x.scraped_at).toISOString()
        : x.scrapedAt
          ? new Date(x.scrapedAt).toISOString()
          : null,
      raw: x, // remove if your table doesn't have a jsonb column named "raw"
    }));

    const targetTable = "stores_apify"; // change if needed

    const { data, error } = await supabase
      .from(targetTable)
      .upsert(rows, { onConflict: "place_id" })
      .select("place_id");

    if (error) {
      return res.status(500).json({ ok: false, error: error.message, hint: error.hint });
    }

    return res.json({ ok: true, ingested: data?.length || 0, table: targetTable });
  } catch (e) {
    return res.status(500).json({ ok: false, error: e?.message || String(e) });
  }
});

// ---------- /api/stores-apify ----------
// MVP: serve directly from "stores" (the table you just populated from Apify)
// Frontend expects rows[].id to exist, so we set id = store_id.
app.get("/api/stores-apify", async (req, res) => {
  try {
    if (!requireSupabase(res, "STORES_APIFY_V1")) return;

    const limit = parseLimit(req.query.limit ?? 200, 200, 2000);
    const qtxt = (req.query.q || "").toString().trim();
    const filters = parseMarketFilters(req);

    let q = supabase
      .from(CFG.STORES)
      .select("store_id, name, address, city, state, created_at")
      .order("created_at", { ascending: false })
      .limit(limit);

    q = applyMarketFilters(q, filters);

    if (qtxt) {
      const esc = qtxt.replace(/,/g, " "); // basic safety for .or string
      q = q.or(`name.ilike.%${esc}%,city.ilike.%${esc}%,state.ilike.%${esc}%,address.ilike.%${esc}%`);
    }

    const { data, error } = await q;
    if (error) throw error;

    // Frontend expects `id` field. Provide stable id = store_id.
    const rows = (data ?? []).map((r) => ({
      id: r.store_id,
      place_id: r.store_id,        // keep compatibility if UI expects place_id
      name: r.name,
      address: r.address,
      street: null,                // not available in this table yet
      city: r.city,
      state: r.state,
      postal_code: null,
      country_code: "US",
      lat: null,
      lng: null,
      total_score: null,
      reviews_count: null,
      scraped_at: r.created_at
    }));

    res.json({
      ok: true,
      signature: "STORES_APIFY_V1",
      build: BUILD,
      last_updated: nowIso(),
      records: rows.length,
      rows,
    });
  } catch (e) {
    console.error("‚ùå /api/stores-apify error:", e);
    respondError(res, "STORES_APIFY_V1", "server_error", 500);
  }
});

// ---------- start ----------
app.listen(PORT, () => {
  console.log(`pb1 backend running on http://localhost:${PORT}`);
});
